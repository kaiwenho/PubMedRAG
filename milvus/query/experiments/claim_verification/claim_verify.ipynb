{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e5a0e1d-9837-4b36-9289-5b88fd9dd833",
   "metadata": {},
   "source": [
    "## Demo: Leveraging Large Language Models (LLMs) to Validate Medical Claims with PubMed Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef9a9f9-adbc-470f-95a7-5a4b7fc5fc8f",
   "metadata": {},
   "source": [
    "This notebook demonstrates a workflow for validating medical claims using Large Language Models (LLMs) alongside scientific evidence sourced from PubMed. The steps are:\n",
    "\n",
    "1. Claim Definition: define a medical claim, provide an edge from a (knowledge) graph, or propose a hypothesis that you want to verify.\n",
    "\n",
    "2. Evidence Retrieval: Utilize Milvus to efficiently search and retrieve relevant sentences from PubMed articles.\n",
    "\n",
    "3. Claim Verification: Apply LLMs to assess the accuracy of the medical claim (defined in step 1) based on the retrieved evidence (from step 2).\n",
    "\n",
    "4. Result Analysis: Present the results provided by the LLMs, and use any statistcs to interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dfd93a-b658-432b-9d30-6d490460a9c8",
   "metadata": {},
   "source": [
    "##### After launching the Milvus container in Docker, wait until at least **1** node is ready to load the collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c179ff-d3a1-4398-b4d0-4a52822fa337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node avialability: 1\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections\n",
    "from pymilvus import utility\n",
    "\n",
    "connections.connect(\n",
    "  alias=\"default\",\n",
    "  uri=\"http://localhost:19530\",\n",
    "  token=\"root:Milvus\",\n",
    ")\n",
    "info = utility.describe_resource_group(name='__default_resource_group')\n",
    "num_available_node = info.num_available_node\n",
    "print(f\"Node avialability: {num_available_node}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548b60b3-b0df-4ee4-8ed6-18f9d09456b0",
   "metadata": {},
   "source": [
    "##### If you see at least \"1\" printed from the cell above, you may continue running the following cells. Otherwise, wait a moment and rerun the cell above until at least \"1\" appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80bd8a7d-30c9-42bf-9a3f-14be45aaeb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "from utils import extract_non_think, generate_claim, embed_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8180b-ed11-436b-9cb8-1ecb114638d8",
   "metadata": {},
   "source": [
    "##### The following cell defines:\n",
    "\n",
    "1. The medical claim or edge you'd like to verify.\n",
    "2. The Milvus collection name (pubmed_sentence_XX, where XX ranges from 00 to 09) to search for supporting evidence.\n",
    "3. The Large Language Model(s) you'd like to use for claim verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5066cf74-f288-4560-8cb7-ff4617977b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  provide an edge with the following format\n",
    "edge = {'subject': 'ginger',\n",
    "        'object': 'nausea',\n",
    "        'predicate': 'Biolink:treats'}\n",
    "claim = generate_claim(edge)\n",
    "\n",
    "# or provide a claim which is a sentence\n",
    "# claim = 'ginger treats nausea'\n",
    "\n",
    "# vectorize the claim for semantic search conducted in the following step\n",
    "claim_vector = embed_sentence(claim)\n",
    "\n",
    "which_collection = 'pubmed_sentence_03'\n",
    "LLMs = ['phi4', 'gemma3:4b', 'deepseek-r1:8b', 'llama3.1:8b', 'mistral:7b']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f349a3db-723f-4eb5-a4d7-65c941ef7c82",
   "metadata": {},
   "source": [
    "##### Connect to the milvus-standalone container and load the collection specified above by which_collection. (This might take a while - about 1 minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff4b24cd-6108-4e3e-835d-f5a6e884cae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time: 50.92s\n"
     ]
    }
   ],
   "source": [
    "client = MilvusClient(\n",
    "    uri=\"http://localhost:19530\",\n",
    "    token=\"root:Milvus\"\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "client.load_collection(\n",
    "    collection_name=which_collection,\n",
    "    # replica_number=1\n",
    ")\n",
    "end = time.time()\n",
    "print(f\"execution time: {(end - start):.2f}s\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c62871-6817-4e97-aa63-0c436d8045ff",
   "metadata": {},
   "source": [
    "##### Perform a semantic search using your claim to retrieve relevant sentences from the Milvus collection with `client.search()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a32c26c7-0199-4c5f-84cd-4d7f2b6ca2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time: 0.11s\n",
      "15 relevant sentences were retrieved from a subset of PubMed.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# semantic search\n",
    "res = client.search(\n",
    "    collection_name=which_collection,  # target collection\n",
    "    data=claim_vector,  # query vectors\n",
    "    limit=30,  # number of returned entities\n",
    "    search_params={\n",
    "        # highlight-start\n",
    "        \"params\": {\n",
    "            \"radius\": 0.75,\n",
    "            \"range_filter\": 1.0\n",
    "        }\n",
    "        # highlight-end\n",
    "    },\n",
    "    output_fields=[\"sentence\", \"pmid\"],  # specifies fields to be returned\n",
    ")\n",
    "end = time.time()\n",
    "print(f\"execution time: {(end - start):.2f}s\") \n",
    "pmids = set([i['entity']['pmid'] for i in res[0]])\n",
    "context = [i['entity']['sentence'] for i in res[0]]\n",
    "print(f\"{len(context)} relevant sentences were retrieved from a subset of PubMed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b97a8-f760-4be4-a516-854b665cd03b",
   "metadata": {},
   "source": [
    "##### Then, generate a prompt using these retrieved sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "747378f9-1b35-455f-a4cd-9e42bbfd87ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt will be used for LLMs queries -\n",
      "Claim: ginger treats nausea\n",
      "Context:\n",
      "Efficacy of ginger for nausea and vomiting: a systematic review of randomized clinical trials.\n",
      "Ginger for nausea.\n",
      "We have performed a systematic review of the evidence from randomized controlled trials for or against the efficacy of ginger for nausea and vomiting.\n",
      "Ginger (Zingiber officinale) has been used to ameliorate symptoms of nausea.\n",
      "Ginger (Zingiber officinale) is often advocated as beneficial for nausea and vomiting.\n",
      "Comparison of efficacy of ginger with various antimotion sickness drugs.\n",
      "Taking ginger for nausea and vomiting during pregnancy.\n",
      "Ginger effectively reduces nausea, tachygastric activity, and vasopressin release induced by circular vection.\n",
      "To determine the effectiveness of ginger for the treatment of nausea and vomiting of pregnancy.\n",
      "Is ginger root effective for decreasing the severity of nausea and vomiting in early pregnancy?\n",
      "Ginger for nausea and vomiting in pregnancy: randomized, double-masked, placebo-controlled trial.\n",
      "The present study indicates the potential of ginger in improving symptoms such as abdominal discomfort and bloating, which may accompany several gastrointestinal illnesses.\n",
      "We hypothesize that ginger ameliorates the nausea associated with motion sickness by preventing the development of gastric dysrhythmias and the elevation of plasma vasopressin.\n",
      "Ginger does not prevent postoperative nausea and vomiting after laparoscopic surgery.\n",
      "Ginger has long been used as an alternative medication to prevent motion sickness.\n",
      "Question: Does the context support the claim? ***Just return Yes or No.***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Claim: {claim}\n",
    "Context:\n",
    "{\"\\n\".join(context)}\n",
    "Question: Does the context support the claim? ***Just return Yes or No.***\n",
    "\"\"\"\n",
    "print(f\"The prompt will be used for LLMs queries -\\n{prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53caa513-1c89-4215-8396-2dbd78daf710",
   "metadata": {},
   "source": [
    "##### Finally, query the LLM(s) you specified earlier, collect their responses, and record the results for statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07082390-228b-4192-84bc-27d657700128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time: 10.72s\n",
      "There were 5 LLMs were queried and returning responses -\n",
      "phi4: Yes. The context supports the claim that ginger treats nausea through various systematic reviews, randomized controlled trials, and studies indicating its efficacy in reducing nausea and vomiting associated with different conditions such as pregnancy, gastrointestinal illnesses, and motion sickness. However, it also notes exceptions where ginger was not effective, like postoperative nausea after laparoscopic surgery. Overall, there is substantial support for the claim within the provided context.\n",
      "gemma3:4b: Yes\n",
      "deepseek-r1:8b: Yes\n",
      "llama3.1:8b: Yes.\n",
      "mistral:7b: Yes.\n",
      "The confident score for this edge being correct is 1.0,\n",
      "with the evidences {12651648, 12371300, 10446026, 12233808, 12576305, 11509171, 11275030, 11876024, 11538042, 10793599}\n"
     ]
    }
   ],
   "source": [
    "LLM_url = \"http://localhost:11434/api/generate\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "results = []\n",
    "responses = []\n",
    "start = time.time()\n",
    "for LLM in LLMs:\n",
    "    data = {\n",
    "        \"model\": LLM,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response = requests.post(LLM_url, headers=headers, data=json.dumps(data))\n",
    "    if response.status_code == 200:\n",
    "        response_text = response.text\n",
    "        data = json.loads(response_text)\n",
    "        actual_resonse = data['response'].strip()\n",
    "        # print(actual_resonse)\n",
    "        if LLM == 'deepseek-r1:8b':\n",
    "            actual_resonse = extract_non_think(actual_resonse)\n",
    "        responses.append(f\"{LLM}: {actual_resonse}\")\n",
    "        if actual_resonse[:3].lower() == 'yes':\n",
    "            results.append(1)\n",
    "        elif actual_resonse[:2].lower() == 'no':\n",
    "            results.append(0)\n",
    "        else:\n",
    "            print(f\"Error: not a proper answer from {LLM}\", actual_resonse)\n",
    "    else:\n",
    "        print(\"Error\", LLM, response.status_code, response.text)\n",
    "end = time.time()\n",
    "print(f\"execution time: {(end - start):.2f}s\") \n",
    "score = sum(results)/len(results)\n",
    "print(f\"There were {len(results)} LLMs were queried and returning responses -\\n{\"\\n\".join(responses)}.\\nThe confident score for this edge being correct is {score},\\nwith the evidences {pmids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "393a79ed-2bb2-494f-87a5-d74109b07ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time: 7.47s\n",
      "There were 5 LLMs were queried and returning responses -\n",
      "mistral:7b: Yes\n",
      "gemma3:4b: Yes\n",
      "llama3.1:8b: Yes.\n",
      "phi4: Yes. \n",
      "\n",
      "The context provides multiple references to studies and trials indicating that ginger is effective in treating nausea in various scenarios, such as during pregnancy and due to motion sickness, although it notes one exception related to postoperative nausea. Overall, the evidence supports the claim that ginger treats nausea.\n",
      "deepseek-r1:8b: Yes.\n",
      "The confident score for this edge being correct is 1.0,\n",
      "with the evidences {12651648, 12371300, 10446026, 12233808, 12576305, 11509171, 11275030, 11876024, 11538042, 10793599}\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "LLM_url = \"http://localhost:11434/api/generate\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "def query_llm(llm_name, prompt):\n",
    "    data = {\n",
    "        \"model\": llm_name,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response = requests.post(LLM_url, headers=headers, data=json.dumps(data))\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        actual_response = response_data['response'].strip()\n",
    "        if llm_name == 'deepseek-r1:8b':\n",
    "            actual_response = extract_non_think(actual_response)\n",
    "        return llm_name, actual_response\n",
    "    else:\n",
    "        return llm_name, f\"Error {response.status_code}: {response.text}\"\n",
    "\n",
    "responses = []\n",
    "results = []\n",
    "\n",
    "start = time.time()\n",
    "with ThreadPoolExecutor(max_workers=len(LLMs)) as executor:\n",
    "    futures = [executor.submit(query_llm, llm, prompt) for llm in LLMs]\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        llm_name, actual_response = future.result()\n",
    "        responses.append(f\"{llm_name}: {actual_response}\")\n",
    "        \n",
    "        if actual_response.lower().startswith('yes'):\n",
    "            results.append(1)\n",
    "        elif actual_response.lower().startswith('no'):\n",
    "            results.append(0)\n",
    "        else:\n",
    "            print(f\"Error: not a proper answer from {llm_name}\", actual_response)\n",
    "end = time.time()\n",
    "print(f\"execution time: {(end - start):.2f}s\")  \n",
    "score = sum(results)/len(results)\n",
    "print(f\"There were {len(results)} LLMs were queried and returning responses -\\n{\"\\n\".join(responses)}.\\nThe confident score for this edge being correct is {score},\\nwith the evidences {pmids}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42f07a-9231-4f07-9bd6-4176989923d7",
   "metadata": {},
   "source": [
    "##### (Optional: Release the collection to optimize RAM usage.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a84fbfd-e089-462e-afa8-407c4d22234e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': <LoadState: NotLoad>}\n"
     ]
    }
   ],
   "source": [
    "client.release_collection(\n",
    "    collection_name=which_collection\n",
    ")\n",
    "\n",
    "res = client.get_load_state(\n",
    "    collection_name=which_collection\n",
    ")\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f40b8f4-a6b1-4d2b-b7c6-80957826fa78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QARAG",
   "language": "python",
   "name": "qarag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
